{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create an image classification solution with Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "\n",
    "# Setup image folder\n",
    "import pathlib\n",
    "\n",
    "data_dir = pathlib.Path('data_set')\n",
    "image_paths = list(data_dir.glob('*/*.jpeg'))\n",
    "print('opening first image:', image_paths[0])\n",
    "PIL.Image.open(str(image_paths[0]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create a set for training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Create a dataset, \n",
    "# the images will be resized automatically using the image_dataset_from_directory() utility\n",
    "batch_size = 5\n",
    "img_height = 180\n",
    "img_width = 180\n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create a set for validating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "find the classnames used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See what an image looks like as a tensor:\n",
    "(it is an array of 180 pixels rows with 180 pixels each (from left to right), each pixel has an RBG color value of [0-255, 0-255, 0-255])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "image0, class0 = list(train_ds)[0]\n",
    "image0\n",
    "#print(np.min(image0), np.max(image0))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize/check the (resized) data using pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# configure plot\n",
    "plt.figure(figsize=(5, 5))\n",
    "for images, labels in train_ds.take(1): # take one batch of 5  \n",
    "  for i in range(len(images)):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    imageArray = images[i].numpy().astype(\"uint8\")    \n",
    "    plt.imshow(imageArray)\n",
    "    plt.title(class_names[labels[i]])\n",
    "    plt.axis(\"off\")\n",
    "#show plot\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "manually iterate over the dataset and retrieve batches of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "for image_batch, labels_batch in train_ds:\n",
    "  print(image_batch.shape)\n",
    "  print(labels_batch.shape)\n",
    "  break # stop after first iteration\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image_batch is a tensor of the shape (5, 180, 180, 3).\n",
    "\n",
    "This is a batch of 5 images of shape 180x180x3 (the last dimension refers to color channels RGB). \n",
    "\n",
    "The label_batch is a tensor of the shape (5,), these are corresponding labels to the 5 images."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RGB channel values are in the [0, 255] range.\n",
    "This is not ideal for a neural network; in general you should seek to make your input values small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "normalization_layer = layers.Rescaling(1./255) # creates a funtion\n",
    "\n",
    "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "image_batch, labels_batch = next(iter(normalized_ds)) #another way to get the first element of the iterable training set\n",
    "first_image = image_batch[0]\n",
    "first_image\n",
    "# Notice the pixel values are now in `[0,1]`.\n",
    "#print(np.min(first_image), np.max(first_image))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A basic (Keras) Sequential Model using Convolution Layers\n",
    "![cnn sees](../basics/.images/how_a_cnn_sees.png)\n",
    "\n",
    "It uses filters to make it easier for the network to recognize features, for instance by finding and highlighting edges.\n",
    "\n",
    "![filter](../basics/.images/filters.png)\n",
    "\n",
    "To see how filters work interactivly [click here](https://deeplizard.com/resource/pavq7noze2)\n",
    "\n",
    "Convolution Network Layers are stacked on top of each other to reduce the information to its essentials.\n",
    "\n",
    "```\n",
    "# Great learning opportunity!\n",
    "It is possible to see what a model with one Conv2D layer does to the input by examining the output when using the predict function, because the model has only one layer the output is the output of the Conv2D layer which is an array of filtered images (= an array of pixels). \n",
    "\n",
    "[watch video](https://pysource.com/2022/08/02/feature-map-computer-vision-with-keras-p-4/)\n",
    "```\n",
    "\n",
    "-------------\n",
    "![features](../basics/.images/conv2d.png)\n",
    "-------------\n",
    "![features](../basics/.images/features.jpg)\n",
    "-------------\n",
    "\n",
    "Because of the feature images are filtered in each layer: Each layer will hold less neurons (=convolution) than its previous layer reducing the images to there bear essence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "num_classes = len(class_names)\n",
    "\n",
    "model = Sequential([\n",
    "  # you could define the definitions of an input layer here but you don't have to\n",
    "  layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'), # 16 different '3x3 filters' result in 16 different features being recognized.\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Flatten(), #flattens from an 2d array of [180, 180] to 1d array [32400]\n",
    "  layers.Dense(128, activation='relu'), # 128 = number of neurons in a network layer, that decide if an image matches\n",
    "  layers.Dense(num_classes) # the last 2 Dense layers will transform the features into output labels\n",
    "])\n",
    "\n",
    "model.summary() # view summary of the model\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile the model\n",
    "\n",
    "Before the model is ready for training, it needs a few more settings. These are added during the model's [*compile*](https://www.tensorflow.org/api_docs/python/tf/keras/Model#compile) step:\n",
    "\n",
    "* [*Loss function*](https://www.tensorflow.org/api_docs/python/tf/keras/losses) —This measures how accurate the model is during training. You want to minimize this function to \"steer\" the model in the right direction.\n",
    "* [*Optimizer*](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers) —This is how the model is updated based on the data it sees and its loss function.\n",
    "* [*Metrics*](https://www.tensorflow.org/api_docs/python/tf/keras/metrics) —Used to monitor the training and testing steps. The following example uses *accuracy*, the fraction of the images that are correctly classified.\n",
    "\n",
    "Choose the *tf.keras.optimizers.Adam optimizer* and *tf.keras.losses.SparseCategoricalCrossentropy* loss function. To view training and validation accuracy for each training epoch, pass the metrics argument to Model.compile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), #Computes how often integer targets are in the top K predictions.\n",
    "  metrics=['accuracy']) #monitor accuracy after each training epoch\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train\n",
    "\n",
    "train the model by fitting the training data and testing the accuracy and then testing the accuracy using the validation data.\n",
    "\n",
    "During the different of epochs (optimization runs) keep a close eay on the *increase* in accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# train the model with only 3! steps\n",
    "model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=3,\n",
    "  verbose=2\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Visualize Training accurracy and Validation accuracy\n",
    "To help you create better models make the training accuracy and validation accuracy visible in a plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# now train it with an additional 10 steps\n",
    "epochs = 10\n",
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs\n",
    ")\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict using data unknown to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "unclassified_image_url = \"https://www.captain-hook.nl/controller/images/003394c0a45a936a58f44658e9fc05d2.jpg\"\n",
    "# save to keras cache\n",
    "unclassified_image_path = tf.keras.utils.get_file('unclassified.jpeg', origin=unclassified_image_url)\n",
    "print(unclassified_image_path)\n",
    "PIL.Image.open(unclassified_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "img = tf.keras.utils.load_img(\n",
    "    unclassified_image_path, target_size=(img_height, img_width)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Improving your model\n",
    "\n",
    "##### Overfitting\n",
    "If the accuracy it start to decline or stagnate (after peaking) it means there is overfitting: \n",
    "The training data starts to fit the model too perfectly! (When there are a small number of training examples, the model sometimes learns from noises or unwanted details from training examples) While the accuracy on the validation set is not improving. Not good: what you really want is to develop models that do well on a data set they haven't seen before.\n",
    "\n",
    "To prevent overfitting, the best solution is to use more training data with examples of what you want to predict. The dataset should cover the full range of inputs that the model is expected to handle. Additional data may only be useful if it covers new and interesting cases.\n",
    "\n",
    "Another way to prevent overfitting is by using **data augmentation**, in our example by supplying a flipped version of the images..\n",
    "\n",
    "##### Underfitting\n",
    "The opposite of overfitting is underfitting. Underfitting occurs when there is still room for improvement on the train data. This can happen for a number of reasons: If the model is not powerful enough, is over-regularized, or has simply not been trained long enough. This means the network has not learned the relevant patterns in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Data augmentation takes the approach of generating additional training data from \n",
    "# your existing examples by augmenting them using random transformations that yield \n",
    "# believable-looking images. This helps expose the model to more aspects of the data \n",
    "# and generalize better.\n",
    "# \n",
    "# uncomment lines below to add more data:\n",
    "model = Sequential([\n",
    " layers.RandomFlip(\"horizontal\",\n",
    "                     input_shape=(img_height,\n",
    "                                 img_width,\n",
    "                                 3)),\n",
    " layers.RandomRotation(0.1),\n",
    " layers.RandomZoom(0.1),\n",
    "  layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(1000, activation='relu'),\n",
    "  layers.Dense(num_classes)\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "  metrics=['accuracy'])\n",
    "  \n",
    "# run previous step to train the model and visualize the plot again"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save model\n",
    "Use TensorFlow Lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Convert the model.\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model.\n",
    "with open('model.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the tflite model in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "TF_MODEL_FILE_PATH = 'model.tflite' # The default path to the saved TensorFlow Lite model\n",
    "\n",
    "interpreter = tf.lite.Interpreter(model_path=TF_MODEL_FILE_PATH)\n",
    "# get input and output\n",
    "interpreter.get_signature_list()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the output from the previous block to identify the runner, first input layer,  and the last output layer\n",
    "\n",
    "i.e. {'serving_default': {'inputs': ['rescaling_3_input'], 'outputs': ['dense_7']}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "runner = 'serving_default'\n",
    "inputs = 'rescaling_3_input'\n",
    "outputs = 'dense_7'\n",
    "\n",
    "classify_lite = interpreter.get_signature_runner(runner)\n",
    "predictions_lite = classify_lite(rescaling_3_input=img_array)[outputs] \n",
    "score_lite = tf.nn.softmax(predictions_lite)\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score_lite)], 100 * np.max(score_lite))\n",
    ")\n",
    "print('dif between normal and lite model prediction', np.max(np.abs(predictions - predictions_lite)))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
