{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras\n",
    "Keras is a python library that builds on the top of TensorFlow\n",
    "It helpers for creating a pipeline (workflow) for building and training the tensorflow model.\n",
    "\n",
    "# The Sequential model\n",
    "A Sequential model is appropriate for a plain stack of layers where each layer has exactly one input tensor and one output tensor. The layers are used as a pipeline to build/train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "\n",
    "# Define Sequential model with 3 layers\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.Dense(2, activation=\"relu\", name=\"layer1\"),\n",
    "        layers.Dense(3, activation=\"relu\", name=\"layer2\"),\n",
    "        layers.Dense(4, name=\"layer3\"),\n",
    "    ])\n",
    "\n",
    "# Call model on a test input\n",
    "x = tf.ones((3, 3))\n",
    "y = model(x)\n",
    "y\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also do the same thing without using a sequential model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Create 3 layers\n",
    "layer1 = layers.Dense(2, activation=\"relu\", name=\"layer1\")\n",
    "layer2 = layers.Dense(3, activation=\"relu\", name=\"layer2\")\n",
    "layer3 = layers.Dense(4, name=\"layer3\")\n",
    "\n",
    "# Call layers on a test input\n",
    "x = tf.ones((3, 3))\n",
    "print(layer1(x))\n",
    "\n",
    "# In a model the output of one layer is used as input in the next layer as we can simulate here\n",
    "y = layer3(layer2(layer1(x)))\n",
    "y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Advanced: If you have more than one input Tensor you cannot use the Sequential model and need to use the Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#advanced example defining you own inputs\n",
    "inputs = tf.keras.Input(shape=(3,))\n",
    "x = tf.keras.layers.Dense(4, activation=tf.nn.relu)(inputs)\n",
    "outputs = tf.keras.layers.Dense(5, activation=tf.nn.softmax)(x)\n",
    "modelFromApi = tf.keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# But what does the layers.Dense() function do?\n",
    "\n",
    "[Neural Networks explained (youtube deeplizard)](https://www.youtube.com/watch?v=sZAlS3_dnk0)\n",
    "\n",
    "\n",
    "A Dense layer feeds all outputs from the previous layer to all its neurons, each neuron providing one output to the next layer. It's the most basic layer in neural networks. A Dense(10) has ten neurons.\n",
    "\n",
    "These are the terms you need to study to better understand a neural network\n",
    "* [Weights & Loss (youtube video)](https://www.youtube.com/watch?v=Skc8nqJirJg) function (uses [Gradients](2_tensor_basics.ipynb#Gradients))\n",
    "* [How is the network learning (youtube video)](https://www.youtube.com/watch?v=N5kpSMDf4o)\n",
    "* [(optional) Backpropagation (youtube video)](https://www.youtube.com/watch?v=XE3krf3CQls) (uses learnable variables)\n",
    "* [(optional) Bias (youtube video)](https://www.youtube.com/watch?v=HetFihsXSys)\n",
    "\n",
    "#### The Dense function\n",
    "It is a function that returns a function that you can configure by specifying the parameters of the Dense(..) function:\n",
    "\n",
    "output = activation(dot(input, kernel) + bias)\n",
    "\n",
    "where\n",
    "* input: represent the input data\n",
    "* kernel: represent the weight data\n",
    "* dot: represent numpy dot product of all input and its corresponding weights\n",
    "* bias: represent a biased value used in machine learning to optimize the model\n",
    "* activation: represent the activation function."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what the function \"dot(input, kernel)\" in a Dense layer looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "input = [ [1, 2], [3, 4] ] \n",
    "kernel = [ [0.5, 0.75], [0.25, 0.5] ] \n",
    "result = np.dot(input, kernel) # product of 2 arrays\n",
    "result # array([[1. , 1.75], [2.5 , 4.25]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examining input and ouput\n",
    "\n",
    "*There is no argument available to specify the input_shape of the input data. \n",
    "input_shape is a special argument, which the layer will accept only if it is designed as first layer in the model.*\n",
    "\n",
    "Examining the model layers input and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input of one layer is the output of the previous layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "print(\"layer0:input\",model.layers[0].input_shape)\n",
    "print(\"layer0:output\",model.layers[0].output_shape)\n",
    "print(\"               v v \")\n",
    "print(\"layer1:input\",model.layers[1].input_shape)\n",
    "print(\"layer1:output\",model.layers[1].output_shape)\n",
    "print(\"               v v \")\n",
    "print(\"layer2:input\",model.layers[2].input_shape)\n",
    "print(\"layer2:output\",model.layers[2].output_shape, \"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weights are initialized (sort of randomly) automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "print(\"layer0:weights\", model.layers[0].get_weights())\n",
    "print(\"layer1:weights\",model.layers[1].get_weights())\n",
    "\n",
    "print(\"layer1:config\",model.layers[1].get_config())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
