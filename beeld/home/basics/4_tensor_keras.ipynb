{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras\n",
    "Keras is a python library that builds on the top of TensorFlow\n",
    "It helpers for creating a pipeline (workflow) for building and training the tensorflow model.\n",
    "\n",
    "# The Sequential model\n",
    "A Sequential model is appropriate for a plain stack of layers where each layer has exactly one input tensor and one output tensor. The layers are used as a pipeline to build/train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "\n",
    "# Define Sequential model with 3 layers\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.Dense(2, activation=\"relu\", name=\"layer1\"),\n",
    "        layers.Dense(3, activation=\"relu\", name=\"layer2\"),\n",
    "        layers.Dense(4, name=\"layer3\"),\n",
    "    ])\n",
    "\n",
    "# Call model on a test input\n",
    "x = tf.ones((3, 3))\n",
    "y = model(x)\n",
    "y\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also do the same thing without using a sequential model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Create 3 layers\n",
    "layer1 = layers.Dense(2, activation=\"relu\", name=\"layer1\")\n",
    "layer2 = layers.Dense(3, activation=\"relu\", name=\"layer2\")\n",
    "layer3 = layers.Dense(4, name=\"layer3\")\n",
    "\n",
    "# Call layers on a test input\n",
    "x = tf.ones((3, 3))\n",
    "print(layer1(x))\n",
    "\n",
    "# In a model the output of one layer is used as input in the next layer as we can simulate here\n",
    "y = layer3(layer2(layer1(x)))\n",
    "y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Advanced: If you have more than one input Tensor you cannot use the Sequential model and need to use the Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#advanced example defining you own inputs\n",
    "inputs = tf.keras.Input(shape=(3,))\n",
    "# the dense function is a function that returns another function, that you can configure by specifying the parameters of the Dense(..) function:\n",
    "x = tf.keras.layers.Dense(4, activation=tf.nn.relu)(inputs)\n",
    "outputs = tf.keras.layers.Dense(5, activation=tf.nn.softmax)(x)\n",
    "modelFromApi = tf.keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# But what does the layers.Dense() function do?\n",
    "\n",
    "To understand the Dense function you have to understand what Neural Networks are.\n",
    "\n",
    "[Neural Networks explained (youtube deeplizard)](https://www.youtube.com/watch?v=sZAlS3_dnk0)\n",
    "\n",
    "\n",
    "A Dense layer feeds all outputs from the previous layer to all its neurons, each neuron providing one output to the next layer. It's the most basic layer in neural networks. A Dense(10) has ten neurons.\n",
    "\n",
    "These are the terms you need to study to better understand a neural network\n",
    "* [Weights & Loss (youtube video)](https://www.youtube.com/watch?v=Skc8nqJirJg) function (uses [Gradients](2_tensor_basics.ipynb#Gradients))\n",
    "* How is the network [learning (youtube video)](https://www.youtube.com/watch?v=N5kpSMDf4o)\n",
    "* (optional) [Backpropagation (youtube video)](https://www.youtube.com/watch?v=XE3krf3CQls) (uses learnable variables)\n",
    "* (optional) [Bias] (youtube video)](https://www.youtube.com/watch?v=HetFihsXSys)\n",
    "\n",
    "\n",
    "#### The Activation function\n",
    "\n",
    "output = activation(dot(input, kernel) + bias)\n",
    "\n",
    "where\n",
    "* input: represent the input data\n",
    "* kernel: represent the weight data\n",
    "* dot: represent numpy dot product of all input and its corresponding weights\n",
    "* bias: represent a biased value used in machine learning to optimize the model\n",
    "* activation: represent the activation function.\n",
    "\n",
    "In Neural Networks, because of there characteristics a **non-lineair** function will be used as activation function.\n",
    "\n",
    "<img src=\".images/non-lineair.webp\" width=\"400\">\n",
    "\n",
    "Using a lineair function would not be helpfull when stacking them in layers, because this would only create one new lineair function.\n",
    "<img src=\".images/lineair.webp\" width=\"400\">\n",
    "\n",
    "\n",
    "There are many non-lineair functions you could used but 'relu' is the most often used:\n",
    "\n",
    "<img src=\".images/relu.png\" width=\"400\">\n",
    "\n",
    "\n",
    "Result of this activation function is treated as output of each neuron and will be used in the next layer as input."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what the function \"dot(input, kernel)\" in a Dense layer looks like. Without the activation function it would just multiply each input of one layer with the weigths for that layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "input = [ [1, 2], [3, 4] ] \n",
    "kernel = [ [0.5, 0.75], [0.25, 0.5] ] \n",
    "result = np.dot(input, kernel) # product of 2 arrays\n",
    "result # array([[1. , 1.75], [2.5 , 4.25]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examining input and ouput of each layer\n",
    "\n",
    "*There is no argument available to specify the input_shape of the input data. \n",
    "input_shape is a special argument, which the layer will accept only if it is designed as first layer in the model.*\n",
    "\n",
    "Examining the model layers input and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input of one layer is the output of the previous layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "print(\"layer0:input\",model.layers[0].input_shape)\n",
    "print(\"layer0:output\",model.layers[0].output_shape)\n",
    "print(\"               v v \")\n",
    "print(\"layer1:input\",model.layers[1].input_shape)\n",
    "print(\"layer1:output\",model.layers[1].output_shape)\n",
    "print(\"               v v \")\n",
    "print(\"layer2:input\",model.layers[2].input_shape)\n",
    "print(\"layer2:output\",model.layers[2].output_shape, \"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weights are initialized (sort of randomly) automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "print(\"layer0:weights\", model.layers[0].get_weights())\n",
    "print(\"layer1:weights\",model.layers[1].get_weights())\n",
    "\n",
    "print(\"layer1:config\",model.layers[1].get_config())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile the model\n",
    "\n",
    "If you want to use the model to make predictions you first have to train it with data.\n",
    "However before the model is ready for training, it needs a few more settings. These are added during the model's [*compile*](https://www.tensorflow.org/api_docs/python/tf/keras/Model#compile) step:\n",
    "\n",
    "* [*Loss function*](https://www.tensorflow.org/api_docs/python/tf/keras/losses) —This measures how accurate the model is during training. You want to minimize the output of this function to \"steer\" the model in the right direction.\n",
    "* [*Optimizer*](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers) —This is how the model is updated based on the data it sees and its loss function.\n",
    "* [*Metrics*](https://www.tensorflow.org/api_docs/python/tf/keras/metrics) —Used to monitor the training and testing steps. The following example uses *accuracy*, the fraction of the images that are correctly classified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  optimizer='adam', # choose the algorithm for optimizing the loss function\n",
    "  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), # choose the algorithm \n",
    "  metrics=['accuracy']) #monitor accuracy after each training epoch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and predict\n",
    "\n",
    "[up next Create, Compile, Train and Predict using an image classification model.](../image_classification/learn.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3c41460b398f69bf470d8af5be98f9ef22a46bd346fdc9d7eba73b064e1e0541"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
