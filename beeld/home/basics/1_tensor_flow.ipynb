{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow\n",
    "\n",
    "Framework for creating machine learning models using a python API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running large calculations on CPU can be slow. When properly configured, TensorFlow can use accelerator hardware like GPUs to execute operations very quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "if tf.config.list_physical_devices('GPU'):\n",
    "  print(\"TensorFlow **IS** using the GPU\")\n",
    "else:\n",
    "  print(\"TensorFlow **IS NOT** using the GPU\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradients\n",
    "\n",
    "The most common type of machine learning is to learn the mapping Y = f(X) to make predictions of Y for new X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "x = tf.Variable(1.0)\n",
    "\n",
    "def f(x):\n",
    "  y = x**2 + 2*x - 5 \n",
    "  return y\n",
    "\n",
    "f(x) # 1 squared + 2*1 - 5 = -2\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The derivative of y is y' = f'(x) = (2*x + 2) = 4. TensorFlow can calculate this automatically.\n",
    "\n",
    "The derivative is a mathmatical caluculation to determine the rate of descent/ascent for y at a given small increase of x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "with tf.GradientTape() as tape: # tape as in a recording tape, it records uses of tf.Variable(1.0)\n",
    "  y = f(x)\n",
    "\n",
    "g_x = tape.gradient(y, x)  # g(x) = dy/dx\n",
    "print([var.name for var in tape.watched_variables()])\n",
    "\n",
    "g_x # 4"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we were to draw the y = f(x) in a graph at the coordinate (x=1, y=-2) the rate of descent would be 4. (move x 1 to the left and y would go up 4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tapes\n",
    "\n",
    "Typically you'll use this to calculate the gradient of a model's error or loss with respect to its weights. \n",
    "\n",
    "Weights are tf.Variables, they are trainable by default.\n",
    "\n",
    "The tape needs to know which operations to record in the forward pass to calculate the gradients in the backwards pass.\n",
    "\n",
    "[up next the basics](2_tensor_basics.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
